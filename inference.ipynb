{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewZhang76/gnn_with_spmm/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-414/714: Deep Learning Systems - Final Project\n",
        "\n",
        "\n",
        "## **Sparse Matrix Multiplication on Graph Neural Network**\n",
        "\n",
        "**By Andrew Zhang, Jinkai Qiu & Yimei Wu**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this project, we are going to implement **sparse matrix** class supported in Needle, **forward and backward pass of sparse matrix multiplication**, and its **application on Graph Neural Network(GNN)**.\n",
        "\n",
        "In this notebook, we are going to show how to **define sparse matrix**, perform **sparse matrix multiplication** and compare it with normal dense matrix multiplication. In addition, we will also show how it can be used in **GNN training.**\n",
        "\n"
      ],
      "metadata": {
        "id": "87NGEASXY4Ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone Required Repo and Install Required Packages"
      ],
      "metadata": {
        "id": "vtBJoltybBDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW1iuoBMCYyp",
        "outputId": "d9917a67-8a3d-4077-80ec-1557e892ff9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/10714\n",
            "/content/drive/MyDrive/10714/final_proj\n",
            "fatal: destination path 'gnn_with_spmm' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 481 bytes | 6.00 KiB/s, done.\n",
            "From https://github.com/AndrewZhang76/gnn_with_spmm\n",
            "   f5a3bf5..ac4dea1  main       -> origin/main\n",
            "Updating fc5d4d1..ac4dea1\n",
            "Fast-forward\n",
            " inference.ipynb             | 782 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " src/ndarray_backend_cuda.cu | 111 \u001b[32m+++++\u001b[m\u001b[31m----\u001b[m\n",
            " 2 files changed, 829 insertions(+), 64 deletions(-)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (2.13.6)\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!mkdir -p final_proj\n",
        "%cd /content/drive/MyDrive/10714/final_proj\n",
        "!git clone https://github.com/AndrewZhang76/gnn_with_spmm.git\n",
        "%cd gnn_with_spmm/\n",
        "!git pull\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build"
      ],
      "metadata": {
        "id": "PidjQAHYbNf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/\n",
        "!make"
      ],
      "metadata": {
        "id": "-U1A2kF6CpzT",
        "outputId": "145fe919-2a54-42d3-e869-93d74baedd3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:57 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- CUDA_FOUND: TRUE\n",
            "-- Found cuda, building cuda backend\n",
            "Mon Dec  9 23:42:58 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0              26W /  70W |    135MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (0.3s)\n",
            "-- Generating done (0.3s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ],
      "metadata": {
        "id": "i4J1P8RQi38J",
        "outputId": "bf8e6289-3dad-4386-9d64-3cc364f1ef3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sparse Matrix Definiation.\n",
        "In this project, we defined a new way to represent a sparse matrix(a type of matrix that contains a significant number of zero elements compared to the total number of elements in the matrix.) - **COO (Coordinate) format**. \\\n",
        "The COO (Coordinate) format is a representation of a sparse matrix that stores only the nonzero elements along with their row and column indices. It is efficient in terms of memory usage for sparse matrices because it avoids storing zero values.\\\n",
        "### Key Components:\n",
        "\n",
        "\n",
        "1.   Values (data): A list or array of the nonzero elements in the matrix.\n",
        "2.   Row indices (row): A list or array specifying the row index for each nonzero element.\n",
        "3. Column indices (col): A list or array specifying the column index for each nonzero element.\n",
        "\n",
        "###Properties:\n",
        "1. Flexible: Allows easy manipulation, such as matrix construction from nonzero entries.\n",
        "2. Duplicates: COO format allows duplicate entries. To obtain the actual matrix, these duplicates need to be summed.\n",
        "3. Conversion: Often converted to other formats like CSR (Compressed Sparse Row) or CSC (Compressed Sparse Column) for efficient matrix operations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NBwt22_ObUkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First, we are going to randomly generate a sparse matrix in normal NDArray format. It is a 10 * 10 matrix with 10 non-zero elements."
      ],
      "metadata": {
        "id": "NBbzz7ACi1sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n",
        "import numpy as np\n",
        "from backend_ndarray.ndarray import *\n",
        "\n",
        "np.random.seed(0)\n",
        "device = cuda()\n",
        "# Dimensions of the matrix\n",
        "rows, cols = 10, 10\n",
        "nonzero_elements = 10\n",
        "\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix = np.zeros((rows, cols))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices = np.random.choice(rows, nonzero_elements, replace=True)\n",
        "col_indices = np.random.choice(cols, nonzero_elements, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values = np.random.random(nonzero_elements)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices, col_indices, values):\n",
        "    matrix[r, c] = v\n",
        "\n",
        "orig_matrix = NDArray(matrix, device=device)\n",
        "orig_matrix"
      ],
      "metadata": {
        "id": "N-Sr6XHhdH7t",
        "outputId": "3845cc2b-bcb8-4fb1-9c54-dd7bbc01b18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Then, we are going to transform it to a sparse matrix."
      ],
      "metadata": {
        "id": "8pAHofaUjG1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix = orig_matrix.to_sparse()\n",
        "sparse_matrix"
      ],
      "metadata": {
        "id": "R3gQhP-3jGYZ",
        "outputId": "d4c40ee1-869f-4c6b-c762-d9ee7ea175b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseMatrix(nnz=8, shape=(10, 10),\n",
              "  data=[0.07103606 0.7991586  0.87001216 0.0202184  0.46147937 0.9786183\n",
              " 0.83261985 0.77815676],\n",
              "  row_indices=[0 2 3 3 4 5 7 9],\n",
              "  col_indices=[6 8 7 8 1 7 1 6])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the sparse matrix contains three length 10 array, `data`, `row_indices` and `col_indices`. The `data` represents the values of the all the non-zero elements inside the matrix, while `row_indices` and `col_indices` represents the row and column index of each non-zero element's index.\n",
        "\n",
        "We can also switch the sparse matrix back to dense matrix by calling `to_dense()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "CPaUh5xojQ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = sparse_matrix.to_dense()\n",
        "dense_matrix"
      ],
      "metadata": {
        "id": "aeLbPoXAkCyq",
        "outputId": "3eb4c6b1-d093-4f4e-a351-d2b58a1db361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sparse Matrix Multiplication\n",
        "### COO Format Matrix Multiplication\n",
        "\n",
        "Matrix multiplication in the **COO (Coordinate)** format involves multiplying two sparse matrices that are represented in the COO format. Since the COO format only stores nonzero elements along with their row and column indices, performing multiplication requires processing each nonzero element and its corresponding coordinates.\n",
        "\n",
        "#### Step 1: Represent the Matrices in COO Format\n",
        "Assume two matrices A and B, both stored in COO format. They are represented by the following components:\n",
        "\n",
        "- **Matrix A**:\n",
        "  - `A_data`: Nonzero values in matrix A.\n",
        "  - `A_row`: Row indices of the nonzero values in A.\n",
        "  - `A_col`: Column indices of the nonzero values in A.\n",
        "\n",
        "- **Matrix B**:\n",
        "  - `B_data`: Nonzero values in matrix B.\n",
        "  - `B_row`: Row indices of the nonzero values in B.\n",
        "  - `B_col`: Column indices of the nonzero values in B.\n",
        "\n",
        "Let matrix A be of size m × n and matrix B be of size n × p. The resulting matrix C will be of size m × p.\n",
        "\n",
        "#### Step 2: Initialize the Resultant Matrix\n",
        "The resulting matrix C will also be sparse and initially contain only zeros. In COO format, the result will have:\n",
        "\n",
        "- `C_data`: Nonzero values of the resulting matrix.\n",
        "- `C_row`: Row indices of the nonzero values in C.\n",
        "- `C_col`: Column indices of the nonzero values in C.\n",
        "\n",
        "#### Step 3: Compute Nonzero Elements of the Result\n",
        "To calculate C = A × B, follow these steps for each nonzero element of A:\n",
        "\n",
        "1. **Find the corresponding element in matrix B**: For each nonzero element A_ij in A, find the corresponding column indices of B. The row index in B must match the column index in A to compute the dot product.\n",
        "\n",
        "2. **Perform the multiplication**: For each pair of nonzero elements A_ij and B_jk, multiply them together and add to the corresponding entry in C:\n",
        "   \n",
        "   ```\n",
        "   C_ik = C_ik + A_ij × B_jk\n",
        "   ```\n",
        "\n",
        "3. **Store the result**: If C_ik is nonzero after the above addition, store the result in the COO format:\n",
        "   - Add the value of C_ik to `C_data`.\n",
        "   - Add the row index i to `C_row`.\n",
        "   - Add the column index k to `C_col`.\n",
        "\n",
        "#### Step 4: Handle Sparse Properties\n",
        "Since the result matrix C is also sparse, ensure that only nonzero values are stored. If the sum of C_ik is zero, it should not be stored in the COO format.\n",
        "#### Define two sparse matrices.\n"
      ],
      "metadata": {
        "id": "V7knxQA5kTql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, p = 500, 500, 500\n",
        "device = cuda()\n",
        "nnz = 100\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix1 = np.zeros((m, n))\n",
        "matrix2 = np.zeros((n, p))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices_1 = np.random.choice(m, nnz, replace=True)\n",
        "col_indices_1 = np.random.choice(n, nnz, replace=True)\n",
        "row_indices_2 = np.random.choice(n, nnz, replace=True)\n",
        "col_indices_2 = np.random.choice(p, nnz, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values_1 = np.random.random(nnz)\n",
        "values_2 = np.random.random(nnz)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices_1, col_indices_2, values_1):\n",
        "    matrix1[r, c] = v\n",
        "for r, c, v in zip(row_indices_2, col_indices_2, values_2):\n",
        "    matrix2[r, c] = v\n",
        "\n",
        "dense_matrix1 = NDArray(matrix1, device=device)\n",
        "dense_matrix2 = NDArray(matrix2, device=device)\n",
        "dense_matrix1, dense_matrix2"
      ],
      "metadata": {
        "id": "SL-cMfnNkkQu",
        "outputId": "cd6d215b-5069-4eeb-ba70-905e59e3c116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()),\n",
              " NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dense matrices to sparse matrices.\n",
        "sparse_matrix1 = dense_matrix1.to_sparse()\n",
        "sparse_matrix2 = dense_matrix2.to_sparse()\n",
        "sparse_matrix1, sparse_matrix2"
      ],
      "metadata": {
        "id": "NHE20CY8l80J",
        "outputId": "89ba7c27-c419-464c-9fd0-d2c435473a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.37416998 0.76532525 0.05537432 0.6304479  0.3960597  0.29214752\n",
              "  0.10029394 0.46357542 0.35561273 0.58641016 0.13248764 0.4783703\n",
              "  0.40724117 0.96157014 0.6178767  0.07952208 0.23170163 0.1314828\n",
              "  0.79920256 0.77058077 0.29302028 0.14484777 0.18327984 0.96193635\n",
              "  0.97749513 0.63947254 0.9473706  0.21550767 0.8638556  0.42468548\n",
              "  0.49739137 0.22431703 0.09784448 0.72559434 0.11753186 0.05342718\n",
              "  0.82211775 0.20747007 0.7168597  0.24536721 0.01323686 0.14694664\n",
              "  0.9065555  0.27762872 0.8621915  0.58678436 0.9037197  0.02566272\n",
              "  0.9295293  0.87650526 0.14814086 0.08342244 0.08960304 0.9608347\n",
              "  0.06395527 0.21331197 0.5654213  0.42053947 0.8605512  0.23223414\n",
              "  0.66991657 0.3472335  0.511319   0.55219245 0.08110139 0.7270443\n",
              "  0.4856276  0.13690028 0.6720478  0.33314514 0.26211816 0.13206811\n",
              "  0.01642963 0.9493188  0.2703279  0.58447605 0.94043195 0.68328136\n",
              "  0.7740473  0.87428796 0.9413777  0.7308558  0.48805627 0.25394166\n",
              "  0.28173012 0.5573688  0.84894353 0.33815897 0.97291946 0.24082878\n",
              "  0.01142746 0.5182007  0.9818294  0.3685846  0.5173791  0.30159864\n",
              "  0.7851529  0.7486636  0.45614058 0.18984792],\n",
              "   row_indices=[ 32  38  42  53  28  42  31  31  53  57  69  47  48  82  84  94  91  98\n",
              "   99  95 121 128 128 105 119 131 147 147 151 127 127 143 148 163 163 169\n",
              "  180 185 183 178 203 197 207 202 227 244 244 265 257 267 262 273 256 279\n",
              "  291 288 290 292 304 305 321 324 334 335 341 349 358 356 369 373 368 370\n",
              "  376 384 387 388 389 405 397 396 398 398 420 423 425 418 426 430 442 442\n",
              "  448 449 452 460 459 461 487 488 487 488],\n",
              "   col_indices=[291 146 120  83 359 396 373 376 241 423 307 480 191 198 174 238 455  81\n",
              "   43  93 297 286 114 357 150 329 254 437 372 368 475 384 470 440 292 136\n",
              "  209 209 323 147 405 379 164 347  63 168 221 129 322 414 345 340  87 106\n",
              "   39 136 291  72  87 195 111 201 442   2 116  13 459 491 160  24 439  25\n",
              "  253 274 314  69 289 203  94 433 348  80  29 446 341 455  93 145  16  44\n",
              "  347 189 498  28 176 372  91 273 320 105]),\n",
              " SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.990345   0.01203622 0.42403224 0.51001686 0.6969972  0.3708528\n",
              "  0.01560606 0.251941   0.85772264 0.3267009  0.58759964 0.9040444\n",
              "  0.37381315 0.39902532 0.5361775  0.03330463 0.06271295 0.39843425\n",
              "  0.72416764 0.13105524 0.69002503 0.9591666  0.37992695 0.07695644\n",
              "  0.1154843  0.3068101  0.16053882 0.3277204  0.15941447 0.25942257\n",
              "  0.5757512  0.7963915  0.79979587 0.75677866 0.8155238  0.8820414\n",
              "  0.7774076  0.49030533 0.69962204 0.4569114  0.9564057  0.9518745\n",
              "  0.45860395 0.45985588 0.6144647  0.54380596 0.03536244 0.6956254\n",
              "  0.18523233 0.57754296 0.39267567 0.61848027 0.2728219  0.59098417\n",
              "  0.09961493 0.28351885 0.22116092 0.90398395 0.63876176 0.9742562\n",
              "  0.0446123  0.94530153 0.25868407 0.05684808 0.4090541  0.12886056\n",
              "  0.86948854 0.6455702  0.0163285  0.9589827  0.9088437  0.8207671\n",
              "  0.18115096 0.7786954  0.42879573 0.06807408 0.5188351  0.9292914\n",
              "  0.9594333  0.43040243 0.3567069  0.9894098  0.8490383  0.4541624\n",
              "  0.4012595  0.2531912  0.24002028 0.23274413 0.19705428 0.35536885\n",
              "  0.03307459 0.62889844 0.16295442 0.6813925  0.45722345 0.7885455\n",
              "  0.1871309  0.45813882 0.2775961  0.6360611 ],\n",
              "   row_indices=[ 36  33  35  24  13  40  61  44  27  27  41  11  79  32  67  73  67  29\n",
              "   43  88 104 111 121 111 133 129 125 138 148 152 151 156 166 182 174 197\n",
              "  184 197 212 189 204 217 215 207 199 214 216 228 218 223 234 232 274 258\n",
              "  259 251 290 291 290 255 267 287 295 287 256 259 265 300 302 297 307 309\n",
              "  326 327 341 353 349 364 374 381 387 382 393 394 434 418 421 429 438 407\n",
              "  423 437 459 466 467 469 486 488 495 491],\n",
              "   col_indices=[ 81 455 491 273 129 372  93  87 297 307 347  39 376 423 221 442  28 329\n",
              "  341  72 459  43  80 359  87 114 274 414 480 291 405 348 323 145 498 111\n",
              "  368 320 150 322 396 174  91 176 440 253 289 437 106 286 357  13 168 433\n",
              "   24 254 160 373 439 314  25 116 209 189 120  69 191 241  16 384 345 201\n",
              "  446 209 379 238 291  94  29 146  63 203 105 195 164 147 455 136 292 470\n",
              "  347 475 372 340  93 136  44  83   2 198]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between dense matrices."
      ],
      "metadata": {
        "id": "vwtVy7Xilioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "correct_result = dense_matrix1 @ dense_matrix2\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "correct_result"
      ],
      "metadata": {
        "id": "PcR5JUpvlaUV",
        "outputId": "1718c2a4-ffe8-46b2-fbba-07ee7f791913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-dense matrix multipliction: 0.2467632293701172 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " ...\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between sparse matrices."
      ],
      "metadata": {
        "id": "mtJqrryEmNso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ sparse_matrix2\n",
        "print(result)\n",
        "result = result.to_dense()\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "rQdvy4RJmXcv",
        "outputId": "5b541aec-afdf-47c6-aea6-33cec1f0e3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseMatrix(nnz=250000, shape=(500, 500),\n",
            "  data=[0.33824366 0.01939528 0.12041055 0.50389314 0.57875663 0.2810014\n",
            " 0.13553244 0.00787358 0.51113176 0.6425616  0.0515544  0.50674784\n",
            " 0.08707694 0.07913516 0.16990964 0.25899497 0.19445834 0.12080467\n",
            " 0.06067465 0.2367718 ],\n",
            "  row_indices=[ 32  57  69  84  99 121 147 265 290 321 321 349 356 358 373 384 420 425\n",
            " 442 449],\n",
            "  col_indices=[373 347 345 498 341 384 475 114 373  43 359 129 198 372 273 168 329 379\n",
            "  87 322])\n",
            "Time taken for sparse-sparse matrix multipliction: 2.4733543395996094 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ dense_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "a-9KWLwRnuyt",
        "outputId": "2e898c24-d060-49da-bc2e-36ca6c245e1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for sparse-dense matrix multipliction: 0.4334449768066406 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = dense_matrix1 @ sparse_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "1ukY2wXRn4dk",
        "outputId": "edac2b5b-2293-4d8b-ac9b-ec1e7acbe0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-sparse matrix multipliction: 0.3123283386230469 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python -m backend_ndarray.ndarray"
      ],
      "metadata": {
        "id": "i7I2JjuJkVLf",
        "outputId": "5865a6f1-d32e-4f3e-e118-e41e31b5f206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'backend_ndarray.ndarray' found in sys.modules after import of package 'backend_ndarray', but prior to execution of 'backend_ndarray.ndarray'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Time for dense @ dense: 0.1761913299560547 ms\n",
            "Time for dense @ sparse: 0.8835792541503906 ms\n",
            "Time for sparse @ dense: 0.1995563507080078 ms\n",
            "Time for sparse @ sparse: 0.06985664367675781 ms\n",
            "Total time: 1.1529922485351562 ms\n",
            "dense @ sparse: True\n",
            "sparse @ dense: True\n",
            "sparse @ sparse: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network(GNN)\n",
        "A Graph Neural Network (GNN) is a type of neural network specifically designed to process and analyze data structured as graphs. In a graph, data is represented as nodes (vertices) connected by edges (links), which may have associated features or attributes.\n",
        "### Common GNN Architectures:\n",
        "1. Graph Convolutional Networks (GCN): Generalizes the concept of convolution to graphs.\n",
        "2. Graph Attention Networks (GAT): Uses attention mechanisms to weigh neighbor contributions.\n",
        "3. GraphSAGE: Focuses on efficient sampling and aggregating information from neighbors.\n",
        "\n",
        "In this project, we are going to implement Graph Convolutional Network(GCN) and use sparse matrix multiplication mechnisms we implemented to accelerate its forward and backward passes."
      ],
      "metadata": {
        "id": "6H_e4ZpKN7G2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrW9hda8kofS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}